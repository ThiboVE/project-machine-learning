{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5778f145",
   "metadata": {},
   "source": [
    "Apparently, scaling does not affect the performance of tree based models so i would not scale the data. For GCN and cVAE it does have an effect so we should scale the data for that, but i would do the datapreprocessing for those models in another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da8359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfe474",
   "metadata": {},
   "source": [
    "Remove redundant features (>0.90 correlation):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f7785",
   "metadata": {},
   "source": [
    "**THERE IS A SMALL PROBLEM IN DROPPING CORRELATED FEATURES**\n",
    "\n",
    "We can't jet drop the correlated features from the full train set for each fold because that would lead to data leakage into the validation set.\n",
    "\n",
    "In this manner, I have decided to remove the correlated features from the inner train sets and apply the same \"mask\" to their respective validation sets.\n",
    "\n",
    "After hyperparameter tuning, when we use the entire train set (train + val) and the test set, we have to do start from the entire train set and calculate the correlated features then.\n",
    "\n",
    "**ChatGPT says the following:**\n",
    "\n",
    "Do not use the per-inner-fold dropped columns directly for the outer test. That would be inconsistent and messy.\n",
    "\n",
    "Best practice: use inner folds only for model selection (compute drops in each inner train â†’ apply to inner val). After you pick the best hyperparameters, recompute the correlated-feature removal once on the full outer training set, and then apply that final mask to the outer test (and to the final model training on the outer-train). That gives a single, consistent feature set per outer fold.\n",
    "\n",
    "Why: the inner-fold removals are for evaluating hyperparameters with realistic training-only transforms. But the final trained model you evaluate on the outer test should be trained with feature selection derived from the full outer training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d80ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"../data/LightGBM/processed/\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(storage_path): os.makedirs(storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065c5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_features_to_drop(X, threshold=0.9) -> list:\n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.90\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401aac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(outer_fold: dict) -> dict:\n",
    "    \n",
    "    for fold in outer_fold['inner_folds']:\n",
    "\n",
    "        X_train, X_val = fold['X_train'], fold['X_val']\n",
    "\n",
    "        # Determine which columns need to be dropped\n",
    "        to_drop = get_correlated_features_to_drop(X_train)\n",
    "        \n",
    "        # Drop in train and validation sets\n",
    "        fold['X_train'] = X_train.drop(columns=to_drop)\n",
    "        fold['X_val'] = X_val.drop(columns=to_drop)\n",
    "\n",
    "    return outer_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d995875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed_outer_fold_0.pkl\n",
      "Saved processed_outer_fold_1.pkl\n",
      "Saved processed_outer_fold_2.pkl\n",
      "Saved processed_outer_fold_3.pkl\n",
      "Saved processed_outer_fold_4.pkl\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    with open(f\"../data/LightGBM/unprocessed/outer_fold_{idx}.pkl\", \"rb\") as f:\n",
    "        outer_fold = pickle.load(f)\n",
    "\n",
    "        new_outer_fold = remove_correlated_features(outer_fold)\n",
    "\n",
    "        # Save outer fold to disk\n",
    "        filename = f\"processed_outer_fold_{idx}.pkl\"\n",
    "        with open((storage_path+filename), \"wb\") as f:\n",
    "            pickle.dump(new_outer_fold, f)\n",
    "\n",
    "        print(f\"Saved {filename}\")\n",
    "\n",
    "        # This step may not be necessary, I don't know\n",
    "        # Free up memory before moving to next outer fold\n",
    "        del outer_fold\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f000b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex',\n",
      "       'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt',\n",
      "       'NumValenceElectrons',\n",
      "       ...\n",
      "       'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene',\n",
      "       'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene',\n",
      "       'fr_unbrch_alkane', 'fr_urea'],\n",
      "      dtype='object', length=217)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/LightGBM/unprocessed/outer_fold_2.pkl\", \"rb\") as f:\n",
    "    outer_fold_2 = pickle.load(f)\n",
    "\n",
    "    inner_fold = outer_fold_2['inner_folds'][0]\n",
    "\n",
    "    print(inner_fold['X_train'].columns)\n",
    "\n",
    "del outer_fold_2, inner_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7a664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed',\n",
      "       'SPS', 'MolWt', 'NumRadicalElectrons', 'MaxPartialCharge',\n",
      "       'MinPartialCharge', 'FpDensityMorgan1',\n",
      "       ...\n",
      "       'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene',\n",
      "       'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene',\n",
      "       'fr_unbrch_alkane', 'fr_urea'],\n",
      "      dtype='object', length=178)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/LightGBM/processed/processed_outer_fold_2.pkl\", \"rb\") as f:\n",
    "    outer_fold_2 = pickle.load(f)\n",
    "\n",
    "    inner_fold = outer_fold_2['inner_folds'][0]\n",
    "\n",
    "    print(inner_fold['X_train'].columns)\n",
    "\n",
    "del outer_fold_2, inner_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c25fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outer_fold_2.keys())\n",
    "# outer_fold_2['inner_folds'][0].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
