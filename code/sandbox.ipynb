{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14573d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from notebooks.library.GCN import ConvolutionLayer, PoolingLayer, GraphData, collate_graph_dataset, Standardizer, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a224a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0bbbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5f906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453524d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QM9 SMILES\n",
    "df_qm9 = pd.read_pickle('data/RDKit/rdkit_only_valid_smiles_qm9.pkl')\n",
    "smiles_list = df_qm9[\"SMILES\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5827659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 24\n",
      "Example tokens: ['<PAD>', '<END>', '<STR>', '#', '(', ')', '+', '-', '/', '1', '2', '3', '4', '5', '=', '@', 'C', 'F', 'H', 'N', 'O', '[', '\\\\', ']']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Collect all unique characters\n",
    "charset = set()\n",
    "for smi in smiles_list:\n",
    "    for ch in smi:\n",
    "        charset.add(ch)\n",
    "\n",
    "# Sort for consistency\n",
    "charset = sorted(list(charset))\n",
    "\n",
    "# Add special tokens\n",
    "special_tokens = ['<PAD>', '<END>', '<STR>']\n",
    "vocab_list = special_tokens + charset\n",
    "\n",
    "# Create token -> index mapping\n",
    "token2idx = {tok: idx for idx, tok in enumerate(vocab_list)}\n",
    "idx2token = {idx: tok for tok, idx in token2idx.items()}\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab_list))\n",
    "print(\"Example tokens:\", vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3040cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "batch_size = 4\n",
    "seq_len = 15                     # sequence length for SMILES\n",
    "vocab_size = len(vocab_list)     # small example vocab\n",
    "latent_dim = 16\n",
    "gru_dim = 32\n",
    "embedding_dim = 8\n",
    "n_layers = 1\n",
    "\n",
    "device = 'cpu'      # or 'cuda' if GPU is available\n",
    "\n",
    "# Dummy input tokens (batch of sequences)\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_len)).to(device)\n",
    "\n",
    "# Dummy target property (HOMO-LUMO gap, for example)\n",
    "y = torch.rand(batch_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f51be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23, 15, 23, 12,  0, 20,  9, 22, 16, 13, 19, 18,  6,  6,  0],\n",
      "        [15, 14, 19, 15, 22,  1, 23,  1, 22, 18,  3,  9,  3, 18,  6],\n",
      "        [ 8, 18, 19, 10, 20,  3,  8,  5,  9,  1,  4, 17, 22,  0,  1],\n",
      "        [ 2, 10, 16, 23,  8, 15, 23,  0, 11, 15,  7, 22, 13,  1, 10]])\n",
      "tensor([[0.2274],\n",
      "        [0.2330],\n",
      "        [0.8268],\n",
      "        [0.0418]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6562909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, dtype=torch.long).to(device) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3482933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = GRU_Decoder(\n",
    "    vocab_size=vocab_size,\n",
    "    latent_dim=latent_dim,\n",
    "    gru_size=gru_dim,\n",
    "    n_layers=n_layers,\n",
    "    embedding_dim=embedding_dim\n",
    ").to(device)\n",
    "\n",
    "encoder = DummyEncoder(gru_dim=gru_dim).to(device)\n",
    "\n",
    "model = cVAE(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    device=device,\n",
    "    latent_dim=latent_dim,\n",
    "    gru_dim=gru_dim,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    teacher_forcing_ratio=0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7204004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, logits, targets, batch_size, beta=1):\n",
    "    recon_loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    loss_recon = recon_loss_fn(logits, targets)\n",
    "    \n",
    "    kl_loss = -0.5 * torch.sum(1 + model.z_logvar - model.z_mean.pow(2) - model.z_logvar.exp()) / batch_size\n",
    "    loss = loss_recon + beta * kl_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e080905",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m outputs = model(x, y)  \u001b[38;5;66;03m# [batch, seq_len, vocab_size]\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# for x, y in ...:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = {\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m: betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m: decoupled_weight_decay,\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py:401\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    398\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:59\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     60\u001b[39m     config,\n\u001b[32m     61\u001b[39m     exc,\n\u001b[32m     62\u001b[39m     graph_break_hints,\n\u001b[32m     63\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     64\u001b[39m     trace_rules,\n\u001b[32m     65\u001b[39m     variables,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     68\u001b[39m     get_indexof,\n\u001b[32m     69\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     70\u001b[39m     livevars_analysis,\n\u001b[32m     71\u001b[39m     propagate_line_nums,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     cleaned_instructions,\n\u001b[32m     75\u001b[39m     create_binary_slice,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     unique_id,\n\u001b[32m     88\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:58\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     52\u001b[39m     getfile,\n\u001b[32m     53\u001b[39m     hashable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     unwrap_if_wrapper,\n\u001b[32m     57\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     BuiltinVariable,\n\u001b[32m     60\u001b[39m     FunctionalCallVariable,\n\u001b[32m     61\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     62\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     63\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     64\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     65\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     66\u001b[39m     ReparametrizeModuleCallVariable,\n\u001b[32m     67\u001b[39m     SkipFunctionVariable,\n\u001b[32m     68\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     69\u001b[39m     UserFunctionVariable,\n\u001b[32m     70\u001b[39m     UserMethodVariable,\n\u001b[32m     71\u001b[39m )\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     75\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/variables/__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:650\u001b[39m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    647\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(typestr, objs))\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:263\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SDPAParamsVariable\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    256\u001b[39m     NumpyNdarrayVariable,\n\u001b[32m    257\u001b[39m     supported_const_comparison_op_values,\n\u001b[32m   (...)\u001b[39m\u001b[32m    261\u001b[39m     UnspecializedPythonVariable,\n\u001b[32m    262\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    264\u001b[39m     DispatchKeySetVariable,\n\u001b[32m    265\u001b[39m     FuncTorchInterpreterVariable,\n\u001b[32m    266\u001b[39m     TorchCtxManagerClassVariable,\n\u001b[32m    267\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m    268\u001b[39m )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_function\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    270\u001b[39m     TensorWithTFOverrideVariable,\n\u001b[32m    271\u001b[39m     torch_function_mode_stack_state_mgr,\n\u001b[32m    272\u001b[39m     TorchFunctionModeVariable,\n\u001b[32m    273\u001b[39m )\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01muser_defined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    275\u001b[39m     FrozenDataClassVariable,\n\u001b[32m    276\u001b[39m     IntWrapperVariable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     UserDefinedTupleVariable,\n\u001b[32m    287\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:156\u001b[39m\n\u001b[32m    140\u001b[39m REWRITE_OPS_TO_TENSOR_SIZE_METHOD = \u001b[38;5;28mdict\u001b[39m.fromkeys(\n\u001b[32m    141\u001b[39m     [\n\u001b[32m    142\u001b[39m         torch._shape_as_tensor,\n\u001b[32m    143\u001b[39m     ]\n\u001b[32m    144\u001b[39m )\n\u001b[32m    146\u001b[39m constant_fold_functions_need_guards = [\n\u001b[32m    147\u001b[39m     torch.accelerator.current_device_index,\n\u001b[32m    148\u001b[39m     torch.cuda.current_device,\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m     torch.xpu.is_initialized,\n\u001b[32m    152\u001b[39m ]\n\u001b[32m    154\u001b[39m constant_fold_functions = [\n\u001b[32m    155\u001b[39m     torch._assert,\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_utils\u001b[49m._get_device_index,\n\u001b[32m    157\u001b[39m     torch._C._get_cublas_allow_tf32,\n\u001b[32m    158\u001b[39m     torch._C._is_any_autocast_enabled,\n\u001b[32m    159\u001b[39m     torch.accelerator.is_available,\n\u001b[32m    160\u001b[39m     torch.cuda.get_device_properties,\n\u001b[32m    161\u001b[39m     torch.cuda.is_available,\n\u001b[32m    162\u001b[39m     torch.distributed.is_available,\n\u001b[32m    163\u001b[39m     torch.get_autocast_dtype,\n\u001b[32m    164\u001b[39m     torch.get_autocast_gpu_dtype,\n\u001b[32m    165\u001b[39m     torch.get_default_dtype,\n\u001b[32m    166\u001b[39m     torch.is_autocast_cache_enabled,\n\u001b[32m    167\u001b[39m     torch.is_autocast_cpu_enabled,\n\u001b[32m    168\u001b[39m     torch.is_autocast_enabled,\n\u001b[32m    169\u001b[39m     torch.is_complex,\n\u001b[32m    170\u001b[39m     torch.is_floating_point,\n\u001b[32m    171\u001b[39m     torch.nn.functional._Reduction.get_enum,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    172\u001b[39m     torch.promote_types,\n\u001b[32m    173\u001b[39m     torch._C._get_privateuse1_backend_name,\n\u001b[32m    174\u001b[39m     torch.autograd._is_checkpoint_valid,\n\u001b[32m    175\u001b[39m     torch.xpu.get_device_properties,\n\u001b[32m    176\u001b[39m     torch.xpu.is_available,\n\u001b[32m    177\u001b[39m ] + constant_fold_functions_need_guards\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.distributed.is_available():\n\u001b[32m    179\u001b[39m     constant_fold_functions.extend(\n\u001b[32m    180\u001b[39m         [\n\u001b[32m    181\u001b[39m             torch.distributed.is_initialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m         ]\n\u001b[32m    185\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/__init__.py:2757\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[32m   2755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2757\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute '_utils'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "outputs = model(x, y)  # [batch, seq_len, vocab_size]\n",
    "\n",
    "# for x, y in ...:\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "logits = outputs.view(-1, vocab_size)\n",
    "targets = x.view(-1)\n",
    "\n",
    "loss = loss_function(model, logits, targets, x.size(0))\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(outputs.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c70f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////<STR>//<STR>/////<STR>\n",
      "4<STR>@C<STR>\\OH<END>(F+H[\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "\n",
    "print(\"\".join([idx2token[i] for i in x[idx].numpy()][1:]))\n",
    "print(\"\".join([idx2token[i] for i in outputs[idx].argmax(1).numpy()][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 15, 24])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(x, y)  # [batch, seq_len, vocab_size]\n",
    "    \n",
    "print(\"Output shape:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token indices:\n",
      " tensor([[ 2,  3,  3,  3,  3,  3, 13,  3,  3, 13,  3,  3,  3,  3, 13],\n",
      "        [ 2,  9,  9,  9,  9, 11, 11,  9,  9, 11,  9,  9,  9,  9, 11],\n",
      "        [ 2,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
      "        [ 2, 12,  3,  6,  6,  3, 18,  6,  3, 18,  3,  3,  3, 18,  3]])\n"
     ]
    }
   ],
   "source": [
    "# pick the most probable token at each step\n",
    "pred_tokens = outputs.argmax(-1)\n",
    "print(\"Predicted token indices:\\n\", pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b86836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4#++#H+#H###H#'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([idx2token[i] for i in pred_tokens[3].numpy()][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88d762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "')\\\\=/12/=<END>][2NO'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([idx2token[i] for i in x[3].numpy()][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564483e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60fb8eb3",
   "metadata": {},
   "source": [
    "How to handle the data:\n",
    "\n",
    "- Convert data to graph repr\n",
    "- Take the SMILES as a vector\n",
    "- Take the target property as a vector\n",
    "\n",
    "- Combine the target variable with teh graph reprs\n",
    "- Run through GCN\n",
    "- Run throught GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1df72da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GraphData(Dataset):\n",
    "    \"\"\"\n",
    "    Class which creates a custom dataset where each datapoint is a molecule/graph with a node matrix, edge matrix, HOMO-LUMO gap and the smiles representation\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_path: str, node_vec_len: int, max_atoms: int):\n",
    "        # Save attributes\n",
    "        self.node_vec_len = node_vec_len\n",
    "        self.max_atoms = max_atoms\n",
    "\n",
    "        # Open dataset file\n",
    "        df = pd.read_pickle(dataset_path)\n",
    "\n",
    "        # Create lists\n",
    "        self.indices = df.index.to_list()[:1]\n",
    "        self.smiles = df[\"SMILES\"].to_list()[:1]\n",
    "        self.outputs = df[\"gaps\"].to_list()[:1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        # Get smile\n",
    "        smile = self.smiles[i]\n",
    "\n",
    "        # Create MolGraph object using the Graph abstraction\n",
    "        mol = Graph(smile, self.node_vec_len, self.max_atoms)\n",
    "\n",
    "        # Get node and adjacency matrices\n",
    "        node_mat = torch.Tensor(mol.node_mat)\n",
    "        adj_mat = torch.Tensor(mol.adj_mat)\n",
    "\n",
    "        # Get output\n",
    "        output = torch.Tensor([self.outputs[i]])\n",
    "\n",
    "        return (node_mat, adj_mat), output, smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1280f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fix seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "use_GPU = torch.cuda.is_available()\n",
    "\n",
    "#### Inputs\n",
    "max_atoms = 50\n",
    "node_vec_len = 30\n",
    "train_size = 0.7\n",
    "batch_size = 1\n",
    "hidden_nodes = 30\n",
    "n_conv_layers = 2\n",
    "n_hidden_layers = 2\n",
    "learning_rate = 0.01\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f637b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start by creating dataset\n",
    "# main_path = Path.cwd().parents[0]\n",
    "data_path = \"data/RDKit/rdkit_only_valid_smiles_qm9.pkl\"\n",
    "dataset = GraphData(dataset_path=data_path, max_atoms=max_atoms, \n",
    "                        node_vec_len=node_vec_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a628086",
   "metadata": {},
   "outputs": [],
   "source": [
    "(node_tensor, adj_tensor), gap, smiles = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1605e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChemGCN(node_vec_len=node_vec_len, node_fea_len=hidden_nodes,\n",
    "                hidden_fea_len=hidden_nodes, n_conv=n_conv_layers, \n",
    "                n_hidden=n_hidden_layers, n_outputs=1, p_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2ffa75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.7363])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ChemGCN.forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m nn_input = (node_mat, adj_mat, output)\n\u001b[32m     28\u001b[39m nn_output = output_std\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m nn_prediction = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnn_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m nn_prediction.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: ChemGCN.forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Standardizer\n",
    "outputs = [dataset[1] for i in range(len(dataset))]\n",
    "standardizer = Standardizer(torch.Tensor(outputs))\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Unpack data\n",
    "node_mat = dataset[0][0]\n",
    "adj_mat = dataset[0][1]\n",
    "output = dataset[1]\n",
    "smiles = dataset[-1]\n",
    "\n",
    "print(output)\n",
    "\n",
    "# Reshape inputs\n",
    "first_dim = int((torch.numel(node_mat)) / (max_atoms * node_vec_len))\n",
    "node_mat = node_mat.reshape(first_dim, max_atoms, node_vec_len)\n",
    "adj_mat = adj_mat.reshape(first_dim, max_atoms, max_atoms)\n",
    "\n",
    "# Standardize output\n",
    "output_std = standardizer.standardize(output)\n",
    "\n",
    "nn_input = (node_mat, adj_mat, output)\n",
    "nn_output = output_std\n",
    "\n",
    "nn_prediction = model(*nn_input)\n",
    "\n",
    "nn_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    epoch,\n",
    "    model,\n",
    "    training_dataloader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    standardizer,\n",
    "    use_GPU,\n",
    "    max_atoms,\n",
    "    node_vec_len,\n",
    "):\n",
    "    \"\"\"\n",
    "    Custom function which defines how a model will be trained (per epoch), here the mean-squared loss between prediction and actual value is used as evaluation metric. This function will perform backpropagation which updates the weights of the networks based in this evaluation.\n",
    "    \"\"\"\n",
    "    # Create variables to store losses and error\n",
    "    avg_loss = 0\n",
    "    avg_mae = 0\n",
    "    count = 0\n",
    "\n",
    "    # Switch model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Go over each batch in the dataloader\n",
    "    for i, dataset in enumerate(training_dataloader):\n",
    "        # Unpack data\n",
    "        node_mat = dataset[0][0]\n",
    "        adj_mat = dataset[0][1]\n",
    "        output = dataset[1]\n",
    "\n",
    "        # Reshape inputs\n",
    "        first_dim = int((torch.numel(node_mat)) / (max_atoms * node_vec_len))\n",
    "        node_mat = node_mat.reshape(first_dim, max_atoms, node_vec_len)\n",
    "        adj_mat = adj_mat.reshape(first_dim, max_atoms, max_atoms)\n",
    "\n",
    "        # Standardize output\n",
    "        output_std = standardizer.standardize(output)\n",
    "\n",
    "        # Package inputs and outputs; check if GPU is enabled\n",
    "        if use_GPU:\n",
    "            nn_input = (node_mat.cuda(), adj_mat.cuda())\n",
    "            nn_output = output_std.cuda()\n",
    "        else:\n",
    "            nn_input = (node_mat, adj_mat)\n",
    "            nn_output = output_std\n",
    "\n",
    "        # Compute output from network\n",
    "        nn_prediction = model(*nn_input)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(nn_output, nn_prediction)\n",
    "        avg_loss += loss\n",
    "\n",
    "        # Calculate MAE\n",
    "        prediction = standardizer.restore(nn_prediction.detach().cpu())\n",
    "        mae = mean_absolute_error(output, prediction)\n",
    "        avg_mae += mae\n",
    "\n",
    "        # Set zero gradients for all tensors\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Do backward prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Update optimizer parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Increase count\n",
    "        count += 1\n",
    "\n",
    "    # Calculate avg loss and MAE\n",
    "    avg_loss = avg_loss / count\n",
    "    avg_mae = avg_mae / count\n",
    "\n",
    "    # Print stats\n",
    "    print(\n",
    "        \"Epoch: [{0}]\\tTraining Loss: [{1:.2f}]\\tTraining MAE: [{2:.2f}]\"\\\n",
    "           .format(\n",
    "                    epoch, avg_loss, avg_mae\n",
    "           )\n",
    "    )\n",
    "\n",
    "    # Return loss and MAE\n",
    "    return avg_loss, avg_mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
