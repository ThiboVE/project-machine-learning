\documentclass[twoside,11pt]{article}

\usepackage{blindtext}
\usepackage{jmlr2e}
\usepackage[style=apa]{biblatex}
\addbibresource{References.bib}
% If you need any other packages, you can add them here.

\usepackage[version=4]{mhchem} %To write nice chemical equations
\usepackage{placeins}%
\usepackage{mathtools}
\usepackage[utf8]{inputenc}
\usepackage[margin=2.5cm]{geometry} %Makes the margin smaller
\usepackage[labelfont=bf, skip=5pt, font=small]{caption} %Needed for nice caption of tables and figures
\usepackage[labelfont=bf, skip=5pt, font=small]{subcaption} %Needed for nice subcaption of tables and figures
\usepackage[export]{adjustbox} %Needed for proper figure adjustment
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref} %To put hyperlinks in the document
\usepackage{pgfplots} %To import pgf files/pictures
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{bookmark}
\usepackage{booktabs}
\usepackage{pgf}
\usepackage{float}
\usepackage{xcolor}
\usepackage{graphicx} % Required for inserting images
\usepackage{wrapfig}
% \usepackage[numbers, super, sort&compress]{natbib}
\usepackage[capitalise]{cleveref}
\usepackage[table,xcdraw]{xcolor} % Voor kleurgebruik in tabelle
\usepackage{siunitx}
\usepackage{url}
\usepackage{pdfpages}
\usepackage{braket}
\usepackage[most]{tcolorbox}
\usepackage{lipsum} % For sample text

% Here you can add any macros you might need.
\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

\usepackage{lastpage}

\crefname{figure}{Figure}{Figures}
\Crefname{figure}{Figure}{Figures}
\crefname{subfigure}{Figure}{Figures}
\Crefname{subfigure}{Figure}{Figures}
\crefname{section}{Section}{Sections}
\Crefname{section}{Section}{Sections}
\crefname{equation}{Equation}{Equations}
\Crefname{equation}{Equation}{Equations}
\crefname{table}{Table}{Tables}

\setlength{\parindent}{0em} %Causes there not to be indentations when creating a new paragraph.

% \numberwithin{equation}{section}
% \numberwithin{table}{section}
% \numberwithin{figure}{section}
% \hypersetup{
%     colorlinks=true,
%     linkcolor=black,
%     filecolor=magenta,      
%     urlcolor=cyan,
%     pdftitle={play},
%     pdfpagemode=FullScreen,
%     citecolor=blue,
%     }
% \bibliographystyle{achemso} 

\firstpageno{1}
\begin{document}

\title{Machine learning for HOMO-LUMO-gap Prediction and Inverse Molecular Design}

\author{\name Mattice Criel
  \AND
  \name Yarno De Jaeger
  \AND
  \name Thibo Van Eeckhoorn}

\maketitle

\begin{abstract}
  In the abstract of your paper, briefly summarize your research in about 150 to 250 words. Briefly explain the problem statement, the techniques you used, and your general results. You can't go into deep detail here, of course, but you don't have to. Think of this as a kind of written ``elevator pitch'': explain your research to someone who has 1-2 minutes time to listen.
\end{abstract}

\section{Introduction}

% In the introduction, give a brief overview of the field your research is in and the problem you are trying to solve or the question you are trying to answer. Then briefly explain what you did and what your conclusions are. This can already be done in a little more detail than in the abstract, but the fully exact description of your methods is for the ``Methods'' section. You can think of this section as an explanation of your research to someone who has 5 to 10 minutes to spare. Below are two more paragraphs of text. As you can see, the first line of a new paragraph is automatically indented. You don't need to change anything here.

Within the spectrum of discrete energy levels (molecular orbitals) in a molecule that can be filled with electrons, the HOMO-lUMO gap is the energy difference between the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO). This is a fundamental descriptor of the electronic structure of a molecule and is strongly influenced by the specific molecular structure and its functional groups. The HOMO-LUMO gap governs key properties such as reactivity, optical absorption and charge transport characteristics and is directly related to the band-gap in conductivity, determining whether a material behaves as a conductor, insulator or semi-conductor\parencite{dwivedi_2025}. The HOMO-LUMO gap also influences the effiency of organic photovoltaics (solar cells based on organic molecules) and organic light-emitting devices (OLED-technology) \parencite{liu_2015}. As a consequence, accurate determination of the HOMO-LUMO gap and design of molecular materials with a specified HOMO-LUMO gap is essential for both materials science and molecular engineering.

Determining the HOMO-LUMO gap, by approximation, is typically done in an experimental setting through optical spectroscopy or voltammetry\parencite{Sworakowski2018,COSTA201651}. However, experimental measurements require synthesized, purified materials making large-scale exploration of hypothetical chemical structures cost expensive and time consuming. As an alternative, methods in computational quantum chemistry, such as Hartree-Fock and Density functional theory (DFT) are used to simulate approximations. Despite their accuracy, these quantum chemical methods are computationally expensive and scale poorly with molecular size and dataset volume, also restricting the capacity of HOMO-LUMO gap exploration and molecular design. 

Machine learning (ML) provides a strategy to overcome these computational limitations\parencite{Hasan2025}. After training, ML models can predict electronic properties with negligible computational cost compared to traditional quantum chemistry. Crucially, large-scale quantum-chemical datasets like QM9, contain extensive information about molecular structures and properties of organic molecules, enabling the development and benchmarking of ML models with the data volume required for robust learning. Beyond property prediction, ML also enables generative molecular design, making it possible to explore hypothetical chemical structures, optimize properties in silico, and drastically reduce the number of costly experiments. This accelerates molecular discovery pipelines, supports safer design exploration, and opens chemical regions that would be impractical to investigate experimentally. 

In this study, we pursue a two-fold objective. First, we build predictive models for HOMO-LUMO gap estimation using both Light Gradient Boosting Model (LightGBM), a high-performance gradient boosting framework and a graph convolutional network (GCN) that learns molecular representations directly from graph topology. Second, we integrate the predictive GCN into a conditional variational autoencoder (cVAE) to generate novel molecular structures with user-specified target HOMO-LUMO gaps. This combined framework enables both accurate property prediction and inverse molecular design, supporting accelerated discovery workflows in molecular design and thereby potentially facilitating a more directed control of specific chemical reactions and increasing the relevance of organic based technology (like OPVs and OLED).

NEED TO ADD A PART ABOUT OUR RESULTS

\section{Related work}
% In the related work section, you briefly describe which other papers have performed research on the same topic as you. Try to explain what the differences are between your research and theirs. You can cite papers like this: \parencite{chow:68}. If you use the citation
% in the middle of a sentence, you can do it like this: \textcite{chow:68} showed that \dots

In recent years, significant progress has been made in predicting HOMO-LUMO gaps using various ML techniques, such as deep learning, ensemble methods, and graph-based models.

\dots

In the context of generative models, variational autoencoders (VAEs) have emerged as a standard framework for de novo molecular design\parencite{walters_2021}. One of the more recent influencial works is done by \textcite{bombarelli_2018}, which adopted a variational autoencoder to optimize the molecular properties in a latent space and uses a Gaussian process to optimize a chemical structure with the desired properties. \textcite{lim_2018} later demonstrated a conditional VAE framework that enables property-controlled molecular generation and serves as a foundational inspiration for our work. Both studies highlight limitations arising from SMILES-based representations and suggest that graph-based encoders and decoders could better capture molecular structure and improve validity, motivating the graph-based generative approach adopted in our research.

TO BE CHANGED

\section{Methodology}
% In this section, explain in detail what you did. Mention exactly what techniques you used, how you implemented everything, what experiments you performed, \dots This section should contain enough detail so that someone else can completely repeat your research.

\subsection{Dataset}
For all models in this study, we used the QM9 dataset\parencite{PyG_QM9}, a widely adopted quantum chemistry dataset comprising 130,831 small organic molecules with associated properties, including the HOMO--LUMO gap. Only molecules with valid SMILES representations were retained, leaving 129,012 molecules, can be seen in \cref{fig:gap_distribution}. SMILES (Simplified Molecular Input Line Entry System) is a text-based notation that encodes chemical structures as ASCII strings, enabling efficient computational processing; for example, benzene is represented as \texttt{C1=CC=CC=C1}. While SMILES strings can be interpreted by computers, they are not directly suitable as input for most machine learning models, which require numerical representations. Consequently, preprocessing is necessary to transform molecular structures into informative, fixed-length numerical features suitable for model training.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/bandgap_distribution_dataset.png}
    \caption{Illustration of the bandgap distribution in the QM9 dataset where only the valid molecules are kept. The vertical dashed lines indicates the minimum and maximum bandgap values in the dataset.}
    \label{fig:gap_distribution}
\end{figure}
\subsection{Molecular Representations and Preprocessing}
In this study, we focus on two different models for HOMO-LUMO gap prediction: LightGBM, a classical machine learning model and GCN, a deep learning model, which require different types of molecular representations. Therefore, two types of molecular representations were generated from the SMILES strings.

\subsubsection{Descriptor-based features for LightGBM}
Using RDKit, a set of 217 molecular descriptors was generated for each molecule from the SMILES representation\parencite{rdkit}. These descriptors capture various aspects of molecular structure and properties, including molecular size, shape, electronic characteristics, surface area, and the presence of functional groups. Together, they provide a fixed-length numerical representation of each molecule suitable for machine learning models such as LightGBM.
    
\subsubsection{Graph-based representation for GCN:}  
For graph neural networks, molecules are represented as graphs where atoms are nodes and bonds are edges. As the QM9 dataset represents molecules as SMILES, all molecule SMILES were translated to a node and edge matrix using the $Chem$ package of $RDKit$\parencite{rdkit_chem_docs}. Node features include atomic number, formal charge, hybridization, aromaticity, and whether the atom is in a ring structure. The edge matrix was defined as an adjacency matrix where the diagonal elements were set to 1, indicating a self-connection, which makes the matrix amenable to convolutions\parencite{deshmukh2023building}. The distance of each bond was included in the edge matrix as 1 over the bond distance. The representation of a molecule as a node and edge matrix allows the GCN to learn structural features directly from molecular graphs without relying on precomputed descriptors.

\subsection{Data Splitting}
To ensure unbiased evaluation, the dataset was split into training, validation, and test sets. For all models, nested cross-validation was used:

\begin{itemize}
    \item \textbf{Outer loop:} 5-fold cross-validation to estimate generalization performance
    \item \textbf{Inner loop:} 10-fold cross-validation for hyperparameter tuning
\end{itemize}

The splits were stratified with 10 bins to preserve the distribution of HOMO-LUMO gaps across the different folds for better results. 

\subsection{LightGBM}
\noindent
LightGBM is a gradient-boosted decision tree algorithm optimized for speed and high-dimensional data. It grows trees in a leaf-wise rather than level-wise manner, allowing it to capture complex, non-linear relationships more efficiently than many traditional boosting methods. This makes it well-suited for tabular molecular descriptor data, as it is robust to feature scaling, multicollinearity, and missing values.
\newline
\noindent
Hyperparameter optimization for the LightGBM model was carried out using Optuna.
The search space included parameters controlling model complexity and regularization:
the number of leaves (num\_leaves, 16--256), the learning rate (learning\_rate, $1\times10^{-3}$--0.1, log-scaled), feature subsampling (feature\_fraction, 0.7--1.0), sample bagging (bagging\_fraction, 0.7--1.0; bagging\_freq, 1--5), and the minimum number of samples per leaf (min\_data\_in\_leaf, 10--100). Other LightGBM settings, such as the boosting type (gbdt) and objective function (regression\_l1), were kept fixed throughout. Optuna selected the optimal hyperparameter configuration by minimizing the mean absolute error (MAE) obtained from the inner loop of the nested cross-validation, using a total of 50 trials.
\newline
\noindent
After nested cross-validation, the best-performing hyperparameters were selected (either by averaging over outer folds or by majority vote). The final LightGBM model was then trained on the entire dataset to produce predictions for comparison with the GCN model.

\subsection{GCN}

The implementation of the GCN model was based on a tutorial about creating a simple Pytorch-based GCN\parencite{deshmukh2023building}. Some edits to the tutorial code were made, for example the addition of node features, the addition of an $R^2$ metric, and correcting a mistake with the standardization of the loss.
\newline
\noindent
Starting from the node and edge matrix representations of a graph, the GCN model first applied a graph convolution using multiple convolution layers. Each convolution layer gives a node information about its neighbors using the matrix multiplication shown in \Cref{fig:graph_conv_layer}. After the convolution layers $pooling$ is applied, which turns the 2-dimensional matrix into a 1-dimensional vector that contains the means of every column of the node matrix. This vector can then be passed to the neural network, which is a simple multilayer perceptron (MLP), a fully connected feedforward neural network. For more details on the implementation, see the GitHub repository \textcolor{red}{add ref to repo}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{img/graph_conv_layer.png}
    \caption{Graph convolution for an acetamide molecule\parencite{deshmukh2023building}.}
    \label{fig:graph_conv_layer}
\end{figure}

\noindent
Hyperparameter optimization for the GCN model was performed using a simple grid search, as this allowed easy parallelization of hyperparameter tuning. The parameters and their possible values included in the grid search are: batch\_size (64, 128, 256, 384), hidden\_nodes (64, 96, 128), n\_conv\_layers (1-5), n\_hidden\_layers (1-3), learning\_rate (0.001, 0.003, 0.005, 0.007, 0.01). Other parameters such as the maximum dimensions of the node and edge matrix, and the number of epochs were kept constant. After nested cross-validation, the same best-performing hyperparameters were obtained for each outer fold: batch\_size = 256, hidden\_nodes = 128, n\_conv\_layers = 4, n\_conv\_layers = 2, learning\_rate = 0.003, the number of epochs was kept constant at 50.

\section{Results}
% Here you describe the results you obtained. This is not just a big data dump where you put all the numbers into one big table. Try to point out patterns or striking things in your results. Think about how you can visualize the results so that a reader, who has not conducted your research themselves, can quickly understand what your results mean.

\section{Discussion}
% Provide an interpretation of your results. What do they mean in the context of your research question? What do you notice here compared to other papers you've read? Perhaps a particular method is not as superior to all the others after all as you originally expected, or maybe you had an idea for a technique that seemed good in theory but doesn't work as well in practice, or \dots

\section{Conclusion}
% Here, you summarize your research and the conclusions you draw from it. Also mention what shortcomings you see in your research. Perhaps there are still certain experiments you would have liked to have done, but didn't have time to do? Think about what steps someone could take to move your research forward.

\section{Disclaimers}
% If you used ChatGPT or other LLMs to do your research and/or write your text, please mention that here. If you used such tools for your research itself, please also mention the prompts you used. Don't be afraid that we will give you a lower grade because you used an LLM. We won't.

\printbibliography
\end{document}